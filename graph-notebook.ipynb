{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the sister-city network\n",
    "## Part 1 : Scraping \n",
    "We start off by writing a simple scraping algorithm that first yields us all the countries. For the data source we will be following along with the [research paper](https://www.researchgate.net/publication/235356930_Not_All_Paths_Lead_to_Rome_Analysing_the_Network_of_Sister_Cities) and using the wikipedia article which constaints the [\"List of towns and sister cities\"](https://en.wikipedia.org/wiki/Lists_of_twin_towns_and_sister_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "PARSER = \"html.parser\"\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Lists_of_twin_towns_and_sister_cities\"\n",
    "\n",
    "html = urlopen(url).read()\n",
    "soup = BeautifulSoup(html, PARSER)\n",
    "\n",
    "continents = soup.find_all(\"span\", {\"class\": \"mw-headline\"})\n",
    "continents = [continent.text.replace(\" \", \"_\") for continent in continents]\n",
    "print(continents)\n",
    "\n",
    "countries = soup.find_all(\"a\", href=lambda href: href and href.replace(\"/wiki/List_of_twin_towns_and_sister_cities_in_\", \"\") not in continents and href.startswith(\"/wiki/List_of_twin_towns_and_sister_cities_in_\"))\n",
    "print(f\"num of countries: {len(countries)}\")\n",
    "cleaned_countries = \"\\n\".join([ country.text.replace(\"List of twin towns and sister cities in \", \"\") for country in countries ])\n",
    "print(cleaned_countries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the countries we simply apply the same idea to get all the cities and respective sister cities. We can then easily generate the graph after cleaning the html. For the sake of simplicity starting off I decided to limit the order of the graph to 100, that is I restricted the number of city nodes to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import bs4\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pprint\n",
    "import csv\n",
    "\n",
    "SOURCE_LINK = \"https://en.m.wikipedia.org\"\n",
    "PARSER = \"html.parser\"\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "sister_cities_dict = dict()\n",
    "\n",
    "\n",
    "def yield_soup(url):\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, PARSER)\n",
    "    return soup\n",
    "\n",
    "\n",
    "def give_next_next(city) -> bs4.element.Tag:\n",
    "    next = city.parent.find_next_sibling()\n",
    "    if next:\n",
    "        next = next.find_next_sibling()\n",
    "\n",
    "    return next or city\n",
    "\n",
    "\n",
    "def give_next(city) -> bs4.element.Tag:\n",
    "    next = city.parent.find_next_sibling()\n",
    "    return next or city\n",
    "\n",
    "\n",
    "def tag_check(city, sister_cities):\n",
    "    if give_next_next(city.parent).name == \"div\":\n",
    "        sister_cities.append(give_next_next(city.parent))\n",
    "        return True\n",
    "    if give_next(city.parent).name == \"ul\":\n",
    "        sister_cities.append(give_next(city.parent))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def generate_edges(country_url):\n",
    "    \"\"\"\n",
    "    Generate edges for the graph between city and all its sister cities\n",
    "    \"\"\"\n",
    "    country_soup = yield_soup(country_url)\n",
    "\n",
    "    cities = country_soup.find_all(\"b\")\n",
    "\n",
    "    sister_cities = []\n",
    "\n",
    "    cities = map(\n",
    "        lambda city: \"\".join(\n",
    "            [\n",
    "                city.text\n",
    "                for city in city.find_all(\"a\")\n",
    "                if (tag_check(city, sister_cities))\n",
    "            ]\n",
    "        ),\n",
    "        cities,\n",
    "    )\n",
    "    cities = list(\n",
    "        filter(lambda city: city != \"\" and city != \"\" and city != \"^\", cities)\n",
    "    )\n",
    "\n",
    "    # find all corresponding sister cities\n",
    "    sister_city_list = list(\n",
    "        map(\n",
    "            lambda sister_city: [\n",
    "                [\n",
    "                    word.lstrip().rstrip()\n",
    "                    for word in re.sub(\n",
    "                        r\"\\[\\d+\\]\",\n",
    "                        \"\",\n",
    "                        (sister_city.parent.text).replace(  # remove citation\n",
    "                            \"\\xa0\", \"\"\n",
    "                        ),  # remove non-breaking space\n",
    "                    ).split(\",\")\n",
    "                ]\n",
    "                for sister_city in sister_city.find_all(\n",
    "                    \"a\", href=lambda href: href and not href.startswith(\"#cite_note\")\n",
    "                )\n",
    "                if sister_city.parent.name != \"span\"\n",
    "            ],\n",
    "            sister_cities,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    adj_list_dict = dict(zip(cities, sister_city_list))\n",
    "    sister_cities_dict.update(adj_list_dict)\n",
    "    pprint.pprint(adj_list_dict)\n",
    "\n",
    "    for k, v in adj_list_dict.items():\n",
    "        for city in v:\n",
    "            G.add_edge(k, city[0])\n",
    "\n",
    "\n",
    "for country in countries:\n",
    "    country_url = SOURCE_LINK + country[\"href\"]\n",
    "    if len(G) < 10:\n",
    "        generate_edges(country_url)\n",
    "\n",
    "# writing the final data\n",
    "with open(\"assets/adj_list.csv\", \"w\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in sister_cities_dict.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Displaying \n",
    "Now if we just use the basic layout for drawing networks then there is alot of overlap with the nodes which makes everything quite unreadable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw_networkx(G, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first observation should be that the nodes are too close together. Also the text overflows the nodes quite heavily. Furhtermore the different components of the graph are scattered quite sporadically. So to fix this we can address each issue step by step. \n",
    "\n",
    "**issue 1 - Nodes too close**\n",
    "\n",
    "To solve the nodes being to close we can use the spring layout. Which quoting the documentation : \n",
    "```\n",
    "... simulates a force-directed representation of the network treating edges as springs holding nodes close, while treating nodes as repelling objects, sometimes called an anti-gravity force\n",
    "```\n",
    "\n",
    "The important parameter here is `k` which as it increases moves nodes further apart from oneanother. I could not figure out any nice way to find a nice value besides brute force so after a little bit of testing I settled on $20\\times \\displaystyle\\frac{1}{\\sqrt{\\text{number of nodes}}}$\n",
    "\n",
    "**issue 2 - Node sizes** \n",
    "\n",
    "Clearly we want the nodes to cover a larger portion of the word to make it look less awkward, to do this we can simply increase the `node_size` argument and maybe also change the color of the nodes and edges to something more pastel to give the graph a less harsh appearance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controls the graph layout\n",
    "pos = nx.spring_layout(G, \n",
    "                       k=20*1/np.sqrt(len(G.nodes())), \n",
    "                       iterations=400,\n",
    "                       scale=1000)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# draw nodes and edges\n",
    "nx.draw(G, pos=pos, \n",
    "        node_size=1000, \n",
    "        node_color='lightblue', \n",
    "        edge_color='gray', \n",
    "        alpha=0.7, \n",
    "        width=0.5)\n",
    "\n",
    "nx.draw_networkx_labels(G, pos=pos, font_size=8)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"assets/graph.svg\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 improving the display using pyvis\n",
    "One of the most prominant issues which is still apparent is that nodes still overlap to the point where it makes certain labels illegible. Here we could play around a bit more networkx but pyviz, which can interface with networkx, might be better suited moving forwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(notebook=True, height=\"1000px\", width=\"1000px\", bgcolor=\"#222222\", font_color=\"white\", cdn_resources='remote')\n",
    "net.from_nx(G)\n",
    "net.show(\"assets/basic_example.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is alot nicer, now lets see scrape a few more cities and then see what our graph looks like. To improve the performance we can disable dragging of the nodes using the `toggle_drag_nodes(false)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    country_url = \"http://en.sistercity.info\" + country[\"href\"]\n",
    "    if len(G) < 500:\n",
    "        generate_edges(country_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(notebook=True, height=\"1000px\", width=\"1000px\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "net.from_nx(G)\n",
    "net.show(\"assets/more_cities.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Final refinements \n",
    "One final change I think would improve the visualization would be to make the degree centrality of a node correspond to its size. This is a simple addition to our display code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(notebook=True, height=\"1000px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "net.from_nx(G)\n",
    "node_degree = dict(G.degree)\n",
    "nx.set_node_attributes(G, node_degree, 'size')\n",
    "net.toggle_drag_nodes(False)\n",
    "net.show(\"assets/all_cities.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Analysis\n",
    "One of the first things I thought would be cool to see would be the network of the sister cities visualized ontop of the worldmap. Similar to the following [image](https://www.researchgate.net/figure/Connections-between-sister-cities-visualised-on-a-world-map-Shorter-connections-are_fig2_235356930) but at a higher resolution.\n",
    "Breaking this problem down : \n",
    "1. I need to get some high resolution image of the world map, something which would hopefully not degrade too much in quality with zooming.\n",
    "2. I would somehow need to correspond each node representing a city with its coordinate on the world map. \n",
    "3. Once I have that I should in theory just be able to render the graph based off the edges I already have stored."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Rendering the image\n",
    "So the first thing that comes to mind with \"high resolution that doesnt degrade in quality with scaling\" is obviously svg, so now the challanges becomes how do we actually display the svg then how do we have the network overlay the svg. \n",
    "Matplotlib can apparently display images and also interface with networkx so lets give that a go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgutils.compose as sc\n",
    "from IPython.display import SVG\n",
    "\n",
    "svg_path = \"assets/world.svg\"\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "fig.savefig(\"assets/cover.svg\", transparent=True)\n",
    "plt.close(fig)\n",
    "\n",
    "# Here starts the assembling using svgutils\n",
    "sc.Figure(\"20cm\", \"10cm\",\n",
    "          sc.SVG(\"assets/world.svg\").scale(0.01),\n",
    "          sc.SVG(\"assets/graph.svg\").scale(0.0025).move(1, 1),\n",
    ").save(\"assets/compose.svg\")\n",
    "\n",
    "SVG(\"assets/compose.svg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, now that worked, doesn't really mean much as it stands but its a nice proof of concept. Clearly the idea works. So onto step 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Mapping the city nodes to coordinates\n",
    "This might be a bit harder. So in practice what this means is that for each node we need some $(x, y)$ coordinate corresponding to its real world coordinates. That is, we need to translate all real world coordinates to the 2D coordinate plane and then scale it all to some desired value. Lets start off by getting a dataset of cities with associated lat/long values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('assets/worldcities.csv')\n",
    "for index, row in df.iterrows():\n",
    "    print(row['city'], row['lat'], row['lng'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that lets see if we can convert the lat and long to a pair of $(x, y)$ coordinates. For this we can use the **Universal Trasverse Mercator Projection**. Which is specifically meant for the purposes of assigning coordinates to locations on the surface of earth. The nice thing is we can use the `utm` python package which handles this conversion for us. After which all we need to do is scale the resulting coordinates to our desired range. Then from this information we can place the nodes on their geographically correct poisitons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utm \n",
    "xmax = 100000\n",
    "ymax = 100000\n",
    "coords = []\n",
    "for index, row in df.iterrows():\n",
    "    lat = row['lat']\n",
    "    lon = row['lng']\n",
    "\n",
    "    # convert lat and lon to utm\n",
    "    x, y, zone, letter = utm.from_latlon(lat, lon)\n",
    "\n",
    "    # scaling x and y down\n",
    "    # x = x / xmax \n",
    "    # y = y / ymax\n",
    "    coords.append((row['city'], x, y))\n",
    "\n",
    "print(coords[0:10])\n",
    "\n",
    "G2 = nx.Graph()\n",
    "\n",
    "for(coord) in coords[0:10]:\n",
    "    print(coord[0], coord[1], coord[2])\n",
    "    G2.add_node(coord[0], pos=(coord[1], coord[2]))\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# draw nodes and edges\n",
    "nx.draw(G2, pos=nx.get_node_attributes(G2,'pos'), \n",
    "        node_size=1000, \n",
    "        node_color='lightblue', \n",
    "        edge_color='gray', \n",
    "        alpha=0.7, \n",
    "        width=0.5)\n",
    "\n",
    "nx.draw_networkx_labels(G2, pos=nx.get_node_attributes(G2,'pos'), font_size=8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "map = Basemap()\n",
    "\n",
    "map.drawcoastlines()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('test.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
