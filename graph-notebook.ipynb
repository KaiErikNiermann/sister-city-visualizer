{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the sister-city network\n",
    "## Part 1 : Scraping \n",
    "We start off by writing a simple scraping algorithm that first yields us all the countries. For the data source we will be following along with the [research paper](https://www.researchgate.net/publication/235356930_Not_All_Paths_Lead_to_Rome_Analysing_the_Network_of_Sister_Cities) and using the wikipedia article which constaints the [\"List of towns and sister cities\"](https://en.wikipedia.org/wiki/Lists_of_twin_towns_and_sister_cities) for the first steps we can get the list of all continents and then countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "PARSER = \"html.parser\"\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Lists_of_twin_towns_and_sister_cities\"\n",
    "\n",
    "html = urlopen(url).read()\n",
    "soup = BeautifulSoup(html, PARSER)\n",
    "\n",
    "continents = soup.find_all(\"span\", {\"class\": \"mw-headline\"})\n",
    "continents = [continent.text.replace(\" \", \"_\") for continent in continents]\n",
    "print(continents)\n",
    "\n",
    "countries = soup.find_all(\"a\", href=lambda href: href and href.replace(\"/wiki/List_of_twin_towns_and_sister_cities_in_\", \"\") not in continents and href.startswith(\"/wiki/List_of_twin_towns_and_sister_cities_in_\"))\n",
    "print(f\"num of countries: {len(countries)}\")\n",
    "cleaned_countries = \"\\n\".join([ country.text.replace(\"List of twin towns and sister cities in \", \"\") for country in countries ])\n",
    "print(cleaned_countries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 finding the pattern\n",
    "Once we have all the countries we can start to see how the html for the actual cities and corresponding sister cities is formatted. While initally I had some confusion as to how to approach this, through testing, I discovered an approach. There was no explicit pattern to link the cities and sister cities so I made use of two ideas \n",
    "1. Intuitively there should be a section of sister cities for each city \n",
    "2. We can read read the cities and sister cities independently, so assuming we read the correct order for both we can construct the adjacency list using the `zip` function on both indepdent arrays.\n",
    "\n",
    "Reading the city sections is rather easy, but making sure we also read the corresponding section for the sister cities required a little more thought. Through some more reading I realized that the tags for the cities has two variants for corresponding tags which contained the sister cities.\n",
    "\n",
    "1. `p` (city tag) -> `misc tag` -> `div` (which contained a list of sister cities)\n",
    "2. `p` (city tag) -> `ul` (contains list of sister cities)\n",
    "\n",
    "So now to read the cities and then corresponding sister cities we just had to read all p tags which either had \n",
    "- the `div` as the 2nd element below \n",
    "- or `ul` as the first element below\n",
    "\n",
    "Once this pattern was apparent the rest of the process was just cleaning the data and finding a proper means of storing it, for which I felt a basic dictionairy with the following format was the most appropraite\n",
    "```\n",
    "{city -> string : sister_cities -> string[]}\n",
    "```\n",
    "\n",
    "Of note here is that the actual city text is nested in the `p` tag, for breviety I just said that the `p` tags correspond to the cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aljezur, Portugal', 'Anadia, Portugal', 'Cabeceiras de Basto, Portugal', 'Felgueiras, Portugal', 'Loulé, Portugal', 'Seixal, Portugal', 'Zocca, Italy']\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import bs4\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pprint\n",
    "import csv\n",
    "\n",
    "SOURCE_LINK = \"https://en.m.wikipedia.org\"\n",
    "PARSER = \"html.parser\"\n",
    "\n",
    "sister_cities_list = dict()\n",
    "\n",
    "def yield_soup(url):\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, PARSER)\n",
    "    return soup\n",
    "\n",
    "def give_nth_below(city, n) -> bs4.element.Tag:\n",
    "    \"\"\"Yields yields the nth element below the given element\n",
    "    \"\"\"\n",
    "    next = city.parent.find_next_sibling()\n",
    "    for i in range(n - 1):\n",
    "        if next:\n",
    "            next = next.find_next_sibling()\n",
    "    return next or city\n",
    "\n",
    "def tag_check(city, sister_cities) -> bool:\n",
    "    \"\"\"Checks if tag for city has corresponding section for sister cities\n",
    "    \"\"\"\n",
    "    first_below = give_nth_below(city.parent, 1)\n",
    "    second_below = give_nth_below(city.parent, 2)\n",
    "    \n",
    "    if first_below.name == \"ul\":\n",
    "        sister_cities.append(first_below)\n",
    "        return True\n",
    "    \n",
    "    if second_below.name == \"div\":\n",
    "        sister_cities.append(second_below)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def generate_edges(country_url):\n",
    "    country_soup = yield_soup(country_url)\n",
    "\n",
    "    cities = country_soup.find_all(\"b\")\n",
    "\n",
    "    sister_cities = []\n",
    "\n",
    "    # cities list \n",
    "    cities = map(\n",
    "        lambda city: \"\".join(\n",
    "            [\n",
    "                city.text\n",
    "                for city in city.find_all(\"a\")\n",
    "                if (tag_check(city, sister_cities))\n",
    "            ]\n",
    "        ),\n",
    "        cities,\n",
    "    )\n",
    "    cities = list(\n",
    "        filter(lambda city: city != \"\" and city != \"\" and city != \"^\", cities)\n",
    "    )\n",
    "\n",
    "    # sister_cities list for corresponding cities\n",
    "    sister_city_list = list(\n",
    "        map(\n",
    "            lambda sister_city: [\n",
    "                \", \".join([                                # joining array back after cleaning\n",
    "                    word.lstrip().rstrip()                 # remove leading and trailing spaces\n",
    "                    for word in re.sub(                    # removing citation\n",
    "                        r\"\\[\\d+\\]\",                        \n",
    "                        \"\",\n",
    "                        (sister_city.parent.text).replace( # remove non-breaking space \n",
    "                            \"\\xa0\", \"\"                      \n",
    "                        ),                                  \n",
    "                    ).split(\",\")                           # splitting to clean individual words\n",
    "                ])\n",
    "                for sister_city in sister_city.find_all(\n",
    "                    \"a\", href=lambda href: href and not href.startswith(\"#cite_note\")\n",
    "                )\n",
    "                if sister_city.parent.name != \"span\"\n",
    "            ],\n",
    "            sister_cities,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    adj_list = dict(zip(cities, sister_city_list))\n",
    "    sister_cities_list.update(adj_list)\n",
    "\n",
    "for country in countries[0:5]: \n",
    "    country_url = SOURCE_LINK + country[\"href\"]\n",
    "    generate_edges(country_url)\n",
    "\n",
    "print(sister_cities_list[\"Boa Vista\"])\n",
    "\n",
    "dataframe = pd.DataFrame.from_dict(sister_cities_list, orient=\"index\")\n",
    "dataframe.to_csv(r\"assets/adj_list.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 writing and reading\n",
    "#### writing \n",
    "Since we don't want to scrape the data each time, especially once we start to work with a larger dataset, it makes sense to save the data. Since our datastructure is rather simple we could just write to it manually, using an approach like the following \n",
    "```python \n",
    "with open('dict.csv', 'w') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in mydict.items():\n",
    "       writer.writerow([key, value])\n",
    "```\n",
    "\n",
    "But using dataframes from the `pandas` we can make this process a bit cleaner by just create a dataframe from the dictionary, orienting it by `index` and then writing it all to a csv. \n",
    "\n",
    "#### reading\n",
    "To read the data back all we need to do is use the `read_csv` function. After which we can reconstruct the original dictionary we used to hold the cities and sister cities. Then from this dictionary we can create our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aljezur, Portugal',\n",
      " 'Anadia, Portugal',\n",
      " 'Cabeceiras de Basto, Portugal',\n",
      " 'Felgueiras, Portugal',\n",
      " 'Loulé, Portugal',\n",
      " 'Seixal, Portugal',\n",
      " 'Zocca, Italy']\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "csv_data = pd.read_csv(r\"assets/adj_list.csv\").to_numpy().tolist()\n",
    "\n",
    "# reconstructing the adjacency list from csv\n",
    "graph_adj_list = dict()\n",
    "for row in csv_data:\n",
    "    key = row[0]\n",
    "    value = list(filter(lambda item: str(item) != 'nan', row[1:len(row)]))\n",
    "    graph_adj_list[key] = value\n",
    "\n",
    "pprint.pprint(graph_adj_list[\"Boa Vista\"])\n",
    "\n",
    "# adding edges to the graph\n",
    "for key, value in graph_adj_list.items():\n",
    "    for item in value:\n",
    "        G.add_edge(key, item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Displaying \n",
    "Now if we just use the basic layout for drawing networks then there is alot of overlap with the nodes which makes everything quite unreadable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw_networkx(G, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first observation should be that the nodes are too close together. Also the text overflows the nodes quite heavily. Furhtermore the different components of the graph are scattered quite sporadically. So to fix this we can address each issue step by step. \n",
    "\n",
    "**issue 1 - Nodes too close**\n",
    "\n",
    "To solve the nodes being to close we can use the spring layout. Which quoting the documentation : \n",
    "```\n",
    "... simulates a force-directed representation of the network treating edges as springs holding nodes close, while treating nodes as repelling objects, sometimes called an anti-gravity force\n",
    "```\n",
    "\n",
    "The important parameter here is `k` which as it increases moves nodes further apart from oneanother. I could not figure out any nice way to find a nice value besides brute force so after a little bit of testing I settled on $20\\times \\displaystyle\\frac{1}{\\sqrt{\\text{number of nodes}}}$\n",
    "\n",
    "**issue 2 - Node sizes** \n",
    "\n",
    "Clearly we want the nodes to cover a larger portion of the word to make it look less awkward, to do this we can simply increase the `node_size` argument and maybe also change the color of the nodes and edges to something more pastel to give the graph a less harsh appearance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controls the graph layout\n",
    "pos = nx.spring_layout(G, \n",
    "                       k=20*1/np.sqrt(len(G.nodes())), \n",
    "                       iterations=400,\n",
    "                       scale=1000)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# draw nodes and edges\n",
    "nx.draw(G, pos=pos, \n",
    "        node_size=1000, \n",
    "        node_color='lightblue', \n",
    "        edge_color='gray', \n",
    "        alpha=0.7, \n",
    "        width=0.5)\n",
    "\n",
    "nx.draw_networkx_labels(G, pos=pos, font_size=8)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"assets/graph.svg\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 improving the display using pyvis\n",
    "One of the most prominant issues which is still apparent is that nodes still overlap to the point where it makes certain labels illegible. Here we could play around a bit more networkx but pyviz, which can interface with networkx, might be better suited moving forwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(notebook=True, height=\"1000px\", width=\"1000px\", bgcolor=\"#222222\", font_color=\"white\", cdn_resources='remote')\n",
    "net.from_nx(G)\n",
    "net.show(\"assets/basic_example.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is alot nicer, now lets see scrape a few more cities and then see what our graph looks like. To improve the performance we can disable dragging of the nodes using the `toggle_drag_nodes(false)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    country_url = \"http://en.sistercity.info\" + country[\"href\"]\n",
    "    if len(G) < 500:\n",
    "        generate_edges(country_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(notebook=True, height=\"1000px\", width=\"1000px\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "net.from_nx(G)\n",
    "net.show(\"assets/more_cities.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 further refinements \n",
    "One final change I think would improve the visualization would be to make the degree centrality of a node correspond to its size. This is a simple addition to our display code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(notebook=True, height=\"1000px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "net.from_nx(G)\n",
    "node_degree = dict(G.degree)\n",
    "nx.set_node_attributes(G, node_degree, 'size')\n",
    "net.toggle_drag_nodes(False)\n",
    "net.show(\"assets/all_cities.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Analysis\n",
    "One of the first things I thought would be cool to see would be the network of the sister cities visualized ontop of the worldmap. Similar to the following [image](https://www.researchgate.net/figure/Connections-between-sister-cities-visualised-on-a-world-map-Shorter-connections-are_fig2_235356930) but at a higher resolution.\n",
    "Breaking this problem down : \n",
    "1. I need to get some high resolution image of the world map, something which would hopefully not degrade too much in quality with zooming.\n",
    "2. I would somehow need to correspond each node representing a city with its coordinate on the world map. \n",
    "3. Once I have that I should in theory just be able to render the graph based off the edges I already have stored."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Rendering the image\n",
    "So the first thing that comes to mind with \"high resolution that doesnt degrade in quality with scaling\" is obviously svg, so now the challanges becomes how do we actually display the svg then how do we have the network overlay the svg. \n",
    "Matplotlib can apparently display images and also interface with networkx so lets give that a go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgutils.compose as sc\n",
    "from IPython.display import SVG\n",
    "\n",
    "svg_path = \"assets/world.svg\"\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "fig.savefig(\"assets/cover.svg\", transparent=True)\n",
    "plt.close(fig)\n",
    "\n",
    "# Here starts the assembling using svgutils\n",
    "sc.Figure(\"20cm\", \"10cm\",\n",
    "          sc.SVG(\"assets/world.svg\").scale(0.01),\n",
    "          sc.SVG(\"assets/graph.svg\").scale(0.0025).move(1, 1),\n",
    ").save(\"assets/compose.svg\")\n",
    "\n",
    "SVG(\"assets/compose.svg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, now that worked, doesn't really mean much as it stands but its a nice proof of concept. Clearly the idea works. So onto step 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Mapping the city nodes to coordinates\n",
    "This might be a bit harder. So in practice what this means is that for each node we need some $(x, y)$ coordinate corresponding to its real world coordinates. That is, we need to translate all real world coordinates to the 2D coordinate plane and then scale it all to some desired value. Lets start off by getting a dataset of cities with associated lat/long values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('assets/worldcities.csv')\n",
    "for index, row in df.iterrows():\n",
    "    print(row['city'], row['lat'], row['lng'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that lets see if we can convert the lat and long to a pair of $(x, y)$ coordinates. For this we can use the **Universal Trasverse Mercator Projection**. Which is specifically meant for the purposes of assigning coordinates to locations on the surface of earth. The nice thing is we can use the `utm` python package which handles this conversion for us. After which all we need to do is scale the resulting coordinates to our desired range. Then from this information we can place the nodes on their geographically correct poisitons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utm \n",
    "xmax = 100000\n",
    "ymax = 100000\n",
    "coords = []\n",
    "for index, row in df.iterrows():\n",
    "    lat = row['lat']\n",
    "    lon = row['lng']\n",
    "\n",
    "    # convert lat and lon to utm\n",
    "    x, y, zone, letter = utm.from_latlon(lat, lon)\n",
    "\n",
    "    # scaling x and y down\n",
    "    # x = x / xmax \n",
    "    # y = y / ymax\n",
    "    coords.append((row['city'], x, y))\n",
    "\n",
    "print(coords[0:10])\n",
    "\n",
    "G2 = nx.Graph()\n",
    "\n",
    "for(coord) in coords[0:10]:\n",
    "    print(coord[0], coord[1], coord[2])\n",
    "    G2.add_node(coord[0], pos=(coord[1], coord[2]))\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# draw nodes and edges\n",
    "nx.draw(G2, pos=nx.get_node_attributes(G2,'pos'), \n",
    "        node_size=1000, \n",
    "        node_color='lightblue', \n",
    "        edge_color='gray', \n",
    "        alpha=0.7, \n",
    "        width=0.5)\n",
    "\n",
    "nx.draw_networkx_labels(G2, pos=nx.get_node_attributes(G2,'pos'), font_size=8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "map = Basemap()\n",
    "\n",
    "map.drawcoastlines()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('test.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
